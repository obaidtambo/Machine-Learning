{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uPXznXDUY4CH",
        "MIfLT-jtaS31",
        "ChCWyAM4cRSd",
        "RRCcIQeZfrG2",
        "AxATdf_HhoU0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing a Mathematical Equation with Tensorflow"
      ],
      "metadata": {
        "id": "ECU4lZ9kXAQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, we will solve the following mathematical equation\n",
        "using TensorFlow:\n",
        "Z=x*x*y+y+c\n",
        "\n",
        "Mathematical equation to be solved using TensorFlow\n",
        "We will use TensorFlow to solve it, as follows:"
      ],
      "metadata": {
        "id": "ZUpDoNegkq7L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqyecGOWWQHS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=tf.Variable(3)\n",
        "Y=tf.Variable(4)"
      ],
      "metadata": {
        "id": "pW-oFqk7WcFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C=tf.constant(2)"
      ],
      "metadata": {
        "id": "3cJwuJuLWf_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def myfunc(x,y,c):\n",
        "    Z=x*x*y+y+c\n",
        "    return Z"
      ],
      "metadata": {
        "id": "vxyq87o3WoTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=myfunc(X,Y,C)\n",
        "tf.print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI_krEIkWtvH",
        "outputId": "679a5a04-8f8d-44f7-ecc8-a7980d86e6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Multiplication Using TensorFlow"
      ],
      "metadata": {
        "id": "2O4d51ViXMHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will use the tf.matmul() method to multiply two\n",
        "matrices using tensorflow. Follow these steps to complete this\n",
        "exercise:"
      ],
      "metadata": {
        "id": "TNgDUP4ek87q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "X=tf.Variable([[1,2,3],[4,5,6]])\n",
        "Y=tf.Variable([[7,8],[9,10],[11,12]])"
      ],
      "metadata": {
        "id": "iFIxy_5lW06U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uOAt4D-XQFN",
        "outputId": "6f39203e-9623-4efd-a10d-45e962a02706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sfyLcVCXRxx",
        "outputId": "ed793d6d-ec91-42c2-fcb0-dd6c79c83cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7 8]\n",
            " [9 10]\n",
            " [11 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c1=tf.matmul(X,Y)"
      ],
      "metadata": {
        "id": "rs3vls-xXVAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.print(c1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHMbcDpVXXhf",
        "outputId": "ef7ce4e1-d3e0-4c0b-9ce0-7854434ddd43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[58 64]\n",
            " [139 154]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c2=tf.matmul(Y,X)"
      ],
      "metadata": {
        "id": "M-4skUEUXe7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.print(c2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2TSY7vNXl9U",
        "outputId": "3e785cea-625c-487f-c782-cb18f23f4c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[39 54 69]\n",
            " [49 68 87]\n",
            " [59 82 105]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reshaping Matrices Using the reshape()Function in TensorFlow"
      ],
      "metadata": {
        "id": "gmD4zlyVXtjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "A=tf.Variable([[1,2,3,4], \\\n",
        "[5,6,7,8], \\\n",
        "[9,10,11,12], \\\n",
        "[13,14,15,16], \\\n",
        "[17,18,19,20]])"
      ],
      "metadata": {
        "id": "IUvMPGgpXo3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P9FoOYqX1Nt",
        "outputId": "dd42fa3a-8f82-4124-e0b8-efda979490e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3 4]\n",
            " [5 6 7 8]\n",
            " [9 10 11 12]\n",
            " [13 14 15 16]\n",
            " [17 18 19 20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUsSoJDzX4F7",
        "outputId": "3b620cfd-6c5e-4811-a977-6df5544c018c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.print(tf.reshape(A,[5,4,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSo7nr7dX69d",
        "outputId": "339cefe8-5368-4925-dbaf-0efd3e8f5247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1]\n",
            "  [2]\n",
            "  [3]\n",
            "  [4]]\n",
            "\n",
            " [[5]\n",
            "  [6]\n",
            "  [7]\n",
            "  [8]]\n",
            "\n",
            " [[9]\n",
            "  [10]\n",
            "  [11]\n",
            "  [12]]\n",
            "\n",
            " [[13]\n",
            "  [14]\n",
            "  [15]\n",
            "  [16]]\n",
            "\n",
            " [[17]\n",
            "  [18]\n",
            "  [19]\n",
            "  [20]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utZqLmgJX96z",
        "outputId": "d8cd18a5-e076-4fd5-ad1f-033379fcf2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = tf.reshape(A,[5,4,1])"
      ],
      "metadata": {
        "id": "sg0enUtmYAmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdP7H0TbYDkg",
        "outputId": "56537b69-9365-4fa3-a7cf-052998e33946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([5, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RteaIxIOYFd3",
        "outputId": "4ee7447d-d09f-4bbe-ec36-adf69241ad68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1]\n",
            "  [2]\n",
            "  [3]\n",
            "  [4]]\n",
            "\n",
            " [[5]\n",
            "  [6]\n",
            "  [7]\n",
            "  [8]]\n",
            "\n",
            " [[9]\n",
            "  [10]\n",
            "  [11]\n",
            "  [12]]\n",
            "\n",
            " [[13]\n",
            "  [14]\n",
            "  [15]\n",
            "  [16]]\n",
            "\n",
            " [[17]\n",
            "  [18]\n",
            "  [19]\n",
            "  [20]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing the argmax() Function"
      ],
      "metadata": {
        "id": "uB9h4-p1YNqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "X=tf.Variable([[91,12,15], [11,88,21],[90, 87,75]])"
      ],
      "metadata": {
        "id": "bUpfndAEYLxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXaq_L_qYTdi",
        "outputId": "63c111bf-f69e-4206-810a-797ae4cb58ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[91 12 15]\n",
            " [11 88 21]\n",
            " [90 87 75]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBmux93aYVgj",
        "outputId": "8ae406ce-7497-414a-a105-3712abe2e5b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.print(tf.argmax(X,axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOxww7w4YX6F",
        "outputId": "b135205d-e7a2-43ce-fc28-49adfef383f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Referring to the matrix in Step 2, we can see that, moving across\n",
        "the columns, the index of the maximum value (91) in the first\n",
        "column is 0. Similarly, the index of the maximum value along\n",
        "the second column (88) is 1. And finally, the maximum value\n",
        "across the third column (75) has index 2. Hence, we have the\n",
        "aforementioned output."
      ],
      "metadata": {
        "id": "R0DIHJ9ElTQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.print(tf.argmax(X,axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHgk7nc6YbZ6",
        "outputId": "ece7f19b-e8ac-4eab-f9c9-17ab37628042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "referring to the matrix in Step 2, if we move along the rows,\n",
        "the maximum value along the first row is 91, which is at index 0.\n",
        "Similarly, the maximum value along the second row is 88, which is at\n",
        "index 1. Finally, the third row is at index 0 again, with a maximum\n",
        "value of 75."
      ],
      "metadata": {
        "id": "lntmi8BDlWLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Exercise 5: Using an Optimizer for a Simple Linear Regression"
      ],
      "metadata": {
        "id": "uPXznXDUY4CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "w=tf.Variable(0.0)\n",
        "b=tf.Variable(0.0)"
      ],
      "metadata": {
        "id": "2VljaIYVYmBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regression(x):\n",
        "    model=w*x+b\n",
        "    return model"
      ],
      "metadata": {
        "id": "mQ8p5yOiZMUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[1,2,3,4]\n",
        "y=[0,-1,-2,-3]"
      ],
      "metadata": {
        "id": "YSBP_jczZQfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss=lambda:abs(regression(x)-y)"
      ],
      "metadata": {
        "id": "Ta0r69NGZXoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=tf.optimizers.Adam(.01)"
      ],
      "metadata": {
        "id": "JA9rmqWgZY_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "    optimizer.minimize(loss,[w,b])"
      ],
      "metadata": {
        "id": "dxruhSjoZgxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# values of the w and b parameters:\n",
        "tf.print(w,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNmU4WZDZlPj",
        "outputId": "0a5e87cf-5e4b-41ba-c5cd-ba4bfb278df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.00371706 0.999803364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.print(regression([1,2,3,4]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMY_R-INZpcH",
        "outputId": "f6ccaa08-3d59-406a-ee08-62f85bc5c617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00391370058 -1.00763083 -2.01134801 -3.01506495]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating an ANN with TensorFlow"
      ],
      "metadata": {
        "id": "MIfLT-jtaS31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "you will create your first sequential ANN in\n",
        "TensorFlow. You will have an input layer, a hidden layer with four\n",
        "units and a ReLU activation function, and an output layer with one\n",
        "unit. Then, you will create some simulation data by generating\n",
        "random numbers and passing it through the model, using the\n",
        "model's predict method to simulate a prediction for each data\n",
        "example."
      ],
      "metadata": {
        "id": "Mu3JH4iiacEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the TensorFlow library:\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "tmhTmSr0Z6-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a Keras model of the sequential class:\n",
        "model = tf.keras.Sequential()"
      ],
      "metadata": {
        "id": "HHOJpuU-aiss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add an input layer to the model using the\n",
        "model's add method, and add the input_shape argument\n",
        "with size (8,) to represent input data with eight features:"
      ],
      "metadata": {
        "id": "WZWXAZGTap8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.InputLayer(input_shape=(8,), \\\n",
        "name='Input_layer'))"
      ],
      "metadata": {
        "id": "IUcHsrvaakcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add two layers of the Dense class to the model. The first will\n",
        "represent your hidden layer with four units and a ReLU activation function, and the second will represent your\n",
        "output layer with one unit:"
      ],
      "metadata": {
        "id": "w9ilpy0Aa1p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dense(4, activation='relu',\\\n",
        "name='First_hidden_layer'))\n",
        "model.add(tf.keras.layers.Dense(1,\\\n",
        "name='Output_layer'))"
      ],
      "metadata": {
        "id": "BYTEP41saySR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "View the weights by calling the variables attribute of the model:"
      ],
      "metadata": {
        "id": "BtcZVuo4bM4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzn89iG_bIbn",
        "outputId": "2af8a78e-bae6-40eb-c2e7-55c1a48ba950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'First_hidden_layer/kernel:0' shape=(8, 4) dtype=float32, numpy=\n",
              " array([[ 0.03206396,  0.5796501 ,  0.67258817,  0.5133162 ],\n",
              "        [ 0.41188568,  0.2060104 , -0.39428276,  0.18558502],\n",
              "        [-0.66977495, -0.3000161 ,  0.07169247, -0.08787888],\n",
              "        [-0.46277136, -0.10706043,  0.64419717,  0.20145673],\n",
              "        [ 0.6782883 , -0.5086755 , -0.3066566 , -0.66842914],\n",
              "        [ 0.05493927,  0.6508911 ,  0.6191067 , -0.32602796],\n",
              "        [ 0.12890965,  0.356319  , -0.45330906,  0.29798716],\n",
              "        [-0.16671574,  0.54987127,  0.32530302, -0.22308749]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'First_hidden_layer/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'Output_layer/kernel:0' shape=(4, 1) dtype=float32, numpy=\n",
              " array([[ 0.04897773],\n",
              "        [ 0.2919097 ],\n",
              "        [-0.9726986 ],\n",
              "        [ 0.32498205]], dtype=float32)>,\n",
              " <tf.Variable 'Output_layer/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This output shows all the variables that compose the model; they\n",
        "include the values for all weights and biases in each layer."
      ],
      "metadata": {
        "id": "vdT32Pd4bYYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of size 32x8, which represents a tensor with\n",
        "# 32 records and 8 features:\n",
        "data = tf.random.normal((32,8))"
      ],
      "metadata": {
        "id": "uUrVKsbEbQeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the predict method of the model and pass in the sample\n",
        "data:"
      ],
      "metadata": {
        "id": "QMdUqilqbhnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(data)\n",
        "# prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e_wv9qCbdIS",
        "outputId": "cfa86c71-d2ca-48f4-8eb8-b797053235f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.1466297e-01],\n",
              "       [ 4.0647754e-04],\n",
              "       [ 1.9386527e-01],\n",
              "       [-1.4814321e+00],\n",
              "       [ 0.0000000e+00],\n",
              "       [-1.0432948e+00],\n",
              "       [ 9.5625764e-01],\n",
              "       [-3.1454825e-01],\n",
              "       [-1.7080228e+00],\n",
              "       [ 4.4960856e-02],\n",
              "       [ 4.4688568e-02],\n",
              "       [ 8.3251648e-02],\n",
              "       [ 1.5288091e-01],\n",
              "       [-4.0611681e-01],\n",
              "       [-1.0621691e+00],\n",
              "       [-7.8553993e-01],\n",
              "       [-9.2656243e-01],\n",
              "       [-3.1090674e-01],\n",
              "       [-5.7185799e-01],\n",
              "       [ 5.5254602e-01],\n",
              "       [ 2.0817879e-01],\n",
              "       [ 6.1287567e-02],\n",
              "       [-5.2836436e-01],\n",
              "       [-2.4305741e-01],\n",
              "       [ 1.5547408e-01],\n",
              "       [-9.2364806e-01],\n",
              "       [ 1.2650713e-02],\n",
              "       [-1.0525322e+00],\n",
              "       [ 4.1989010e-02],\n",
              "       [-1.7544633e-01],\n",
              "       [ 1.2411952e+00],\n",
              "       [ 0.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the ANN after random inputs have been applied"
      ],
      "metadata": {
        "id": "M7dm87ZGcAnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the predict() method on the sample data will propagate the\n",
        "data through the network. In each layer, there will be a matrix\n",
        "multiplication of the data with the weights, and the bias will be added\n",
        "before the data is passed as input data to the next layer. This process\n",
        "continues until the final output layer."
      ],
      "metadata": {
        "id": "uroCGtgKcCgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You initialized a model, added an input layer to accept data with eight\n",
        "\n",
        "features, added a hidden layer with four units, and added an output\n",
        "layer with one unit. Before fitting a model to training data, you must\n",
        "first compile the model with an optimizer and choose a loss function\n",
        "to minimize the value it computes by updating weights in the\n",
        "training process."
      ],
      "metadata": {
        "id": "bc4D3djscMqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Linear Regression Model as an ANN with TensorFlow"
      ],
      "metadata": {
        "id": "ChCWyAM4cRSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "you will create a linear regression model as an ANN\n",
        "using TensorFlow. The dataset, Bias_correction_ucl.csv,\n",
        "describes the bias correction of air temperature forecasts of Seoul,\n",
        "South Korea. The fields represent temperature measurements of the\n",
        "given date, the weather station at which the metrics were measured,\n",
        "model forecasts of weather-related metrics such as humidity, and\n",
        "projections for the temperature the following day. You are required\n",
        "to predict the next maximum and minimum temperature given\n",
        "measurements of the prior timepoints and attributes of the weather\n",
        "station."
      ],
      "metadata": {
        "id": "sDV07K4_cYuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the TensorFlow and pandas libraries:\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "_Qn_C1sgci36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Bias_correction_ucl.csv')"
      ],
      "metadata": {
        "id": "el3s5wjQcmOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the date column and drop any rows that have null\n",
        "# values since your model requires numerical values only:\n",
        "df.drop('Date', inplace=True, axis=1)\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "eUKW257fc6KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create target and feature datasets. The target dataset will\n",
        "contain the columns named Next_Tmax and Next_Tmin,\n",
        "\n",
        "while the feature dataset will contain all columns except\n",
        "those named Next_Tmax and Next_Tmin:"
      ],
      "metadata": {
        "id": "6n-XMNz6dBHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = df[['Next_Tmax', 'Next_Tmin']]\n",
        "features = df.drop(['Next_Tmax', 'Next_Tmin'],axis=1)"
      ],
      "metadata": {
        "id": "rr92pseHc7Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rescale the feature dataset:"
      ],
      "metadata": {
        "id": "SxK0CMbpdRnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescale the feature dataset:\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "feature_array = scaler.fit_transform(features)\n",
        "features = pd.DataFrame(feature_array,\n",
        "columns=features.columns)"
      ],
      "metadata": {
        "id": "m1YlYzjodF12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a Keras model of the Sequential class:\n",
        "model = tf.keras.Sequential()"
      ],
      "metadata": {
        "id": "SW1B60tGdXD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add an input layer to the model using the\n",
        "model's add method, and set input_shape to be the number\n",
        "of columns in the feature dataset:"
      ],
      "metadata": {
        "id": "BGl0NrbudkEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.InputLayer\\\n",
        "(input_shape=(features.shape[1],), \\\n",
        "name='Input_layer'))"
      ],
      "metadata": {
        "id": "K4nDRf9idfp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the output layer of the Dense class to the model with a\n",
        "size of 2, representing the two target variables:"
      ],
      "metadata": {
        "id": "2wf-M3RHdxy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dense(2,\n",
        "name='Output_layer'))"
      ],
      "metadata": {
        "id": "4m_MMf17dnd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model with an RMSprop optimizer and a mean\n",
        "squared error loss:"
      ],
      "metadata": {
        "id": "Vry03IgYeFGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(tf.optimizers.RMSprop(0.001),\n",
        "loss='mse')"
      ],
      "metadata": {
        "id": "IGh7IPzfd0rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a callback for TensorBoard:\n",
        "tensorboard_callback = tf.keras.callbacks\\\n",
        ".TensorBoard(log_dir=\"./logs\")"
      ],
      "metadata": {
        "id": "EMr9O_NneI4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the training data:\n",
        "model.fit(x=features.to_numpy(),\n",
        "y=target.to_numpy(),\\\n",
        "epochs=50,\n",
        "callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiB2-ptheSNc",
        "outputId": "18f76e40-ff71-47f6-d0c8-b3591205a286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "238/238 [==============================] - 1s 886us/step - loss: 625.9849\n",
            "Epoch 2/50\n",
            "238/238 [==============================] - 0s 887us/step - loss: 524.7980\n",
            "Epoch 3/50\n",
            "238/238 [==============================] - 0s 873us/step - loss: 433.2907\n",
            "Epoch 4/50\n",
            "238/238 [==============================] - 0s 897us/step - loss: 351.5018\n",
            "Epoch 5/50\n",
            "238/238 [==============================] - 0s 902us/step - loss: 279.1596\n",
            "Epoch 6/50\n",
            "238/238 [==============================] - 0s 911us/step - loss: 216.4005\n",
            "Epoch 7/50\n",
            "238/238 [==============================] - 0s 916us/step - loss: 163.3060\n",
            "Epoch 8/50\n",
            "238/238 [==============================] - 0s 900us/step - loss: 119.6622\n",
            "Epoch 9/50\n",
            "238/238 [==============================] - 0s 971us/step - loss: 85.6823\n",
            "Epoch 10/50\n",
            "238/238 [==============================] - 0s 895us/step - loss: 61.0546\n",
            "Epoch 11/50\n",
            "238/238 [==============================] - 0s 898us/step - loss: 44.2384\n",
            "Epoch 12/50\n",
            "238/238 [==============================] - 0s 937us/step - loss: 33.0717\n",
            "Epoch 13/50\n",
            "238/238 [==============================] - 0s 1ms/step - loss: 26.3159\n",
            "Epoch 14/50\n",
            "238/238 [==============================] - 0s 921us/step - loss: 22.3933\n",
            "Epoch 15/50\n",
            "238/238 [==============================] - 0s 886us/step - loss: 19.7858\n",
            "Epoch 16/50\n",
            "238/238 [==============================] - 0s 934us/step - loss: 17.8378\n",
            "Epoch 17/50\n",
            "238/238 [==============================] - 0s 921us/step - loss: 16.1529\n",
            "Epoch 18/50\n",
            "238/238 [==============================] - 0s 932us/step - loss: 14.6013\n",
            "Epoch 19/50\n",
            "238/238 [==============================] - 0s 921us/step - loss: 13.1974\n",
            "Epoch 20/50\n",
            "238/238 [==============================] - 0s 898us/step - loss: 11.9803\n",
            "Epoch 21/50\n",
            "238/238 [==============================] - 0s 921us/step - loss: 10.9149\n",
            "Epoch 22/50\n",
            "238/238 [==============================] - 0s 947us/step - loss: 9.9512\n",
            "Epoch 23/50\n",
            "238/238 [==============================] - 0s 907us/step - loss: 9.0644\n",
            "Epoch 24/50\n",
            "238/238 [==============================] - 0s 944us/step - loss: 8.2934\n",
            "Epoch 25/50\n",
            "238/238 [==============================] - 0s 946us/step - loss: 7.6132\n",
            "Epoch 26/50\n",
            "238/238 [==============================] - 0s 896us/step - loss: 7.0349\n",
            "Epoch 27/50\n",
            "238/238 [==============================] - 0s 955us/step - loss: 6.5256\n",
            "Epoch 28/50\n",
            "238/238 [==============================] - 0s 909us/step - loss: 6.0832\n",
            "Epoch 29/50\n",
            "238/238 [==============================] - 0s 893us/step - loss: 5.7083\n",
            "Epoch 30/50\n",
            "238/238 [==============================] - 0s 871us/step - loss: 5.4169\n",
            "Epoch 31/50\n",
            "238/238 [==============================] - 0s 937us/step - loss: 5.1777\n",
            "Epoch 32/50\n",
            "238/238 [==============================] - 0s 935us/step - loss: 4.9639\n",
            "Epoch 33/50\n",
            "238/238 [==============================] - 0s 913us/step - loss: 4.7892\n",
            "Epoch 34/50\n",
            "238/238 [==============================] - 0s 908us/step - loss: 4.6438\n",
            "Epoch 35/50\n",
            "238/238 [==============================] - 0s 916us/step - loss: 4.5193\n",
            "Epoch 36/50\n",
            "238/238 [==============================] - 0s 947us/step - loss: 4.4153\n",
            "Epoch 37/50\n",
            "238/238 [==============================] - 0s 862us/step - loss: 4.3238\n",
            "Epoch 38/50\n",
            "238/238 [==============================] - 0s 913us/step - loss: 4.2415\n",
            "Epoch 39/50\n",
            "238/238 [==============================] - 0s 900us/step - loss: 4.1609\n",
            "Epoch 40/50\n",
            "238/238 [==============================] - 0s 946us/step - loss: 4.0894\n",
            "Epoch 41/50\n",
            "238/238 [==============================] - 0s 910us/step - loss: 4.0244\n",
            "Epoch 42/50\n",
            "238/238 [==============================] - 0s 910us/step - loss: 3.9592\n",
            "Epoch 43/50\n",
            "238/238 [==============================] - 0s 901us/step - loss: 3.8998\n",
            "Epoch 44/50\n",
            "238/238 [==============================] - 0s 927us/step - loss: 3.8436\n",
            "Epoch 45/50\n",
            "238/238 [==============================] - 0s 963us/step - loss: 3.7896\n",
            "Epoch 46/50\n",
            "238/238 [==============================] - 0s 903us/step - loss: 3.7391\n",
            "Epoch 47/50\n",
            "238/238 [==============================] - 0s 937us/step - loss: 3.6899\n",
            "Epoch 48/50\n",
            "238/238 [==============================] - 0s 877us/step - loss: 3.6462\n",
            "Epoch 49/50\n",
            "238/238 [==============================] - 0s 941us/step - loss: 3.6017\n",
            "Epoch 50/50\n",
            "238/238 [==============================] - 0s 960us/step - loss: 3.5579\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff8f8ceabd0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data:\n",
        "loss = model.evaluate(features.to_numpy(),\n",
        "target.to_numpy())\n",
        "print('loss:', loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUMzJx4eegK_",
        "outputId": "4b1a566a-1a1b-4daf-dd3d-09697f070b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "238/238 [==============================] - 0s 748us/step - loss: 3.5355\n",
            "loss: 3.535490036010742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "you have learned how to create, train, and evaluate\n",
        "an ANN with TensorFlow by using Keras layers. You recreated the\n",
        "linear regression algorithm by creating an ANN with an input layer\n",
        "and an output layer that has one unit for each output. Here, there\n",
        "were two outputs representing the maximum and minimum values of\n",
        "the temperature; thus, the output layer has two units."
      ],
      "metadata": {
        "id": "KgTVJVcTfGN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating a Multi-Layer ANN with TensorFlow\n"
      ],
      "metadata": {
        "id": "RRCcIQeZfrG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "you will create a multi-layer ANN using TensorFlow.\n",
        "This model will have four hidden layers. You will add multiple layers\n",
        "to the model and activation functions to the output of the layers. The\n",
        "first hidden layer will have 16 units, the second will have 8 units, and\n",
        "the third will have 4 units. The output layer will have 2 units."
      ],
      "metadata": {
        "id": "-TBeuFnmf171"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset, Bias_correction_ucl.csv, describes the bias correction of air temperature forecasts of Seoul, South Korea. The fields represent temperature measurements of the given date, the weather station at which the metrics were measured, model forecasts of weather-related metrics such as humidity, and projections for the temperature the following day. You are required to predict the next maximum and minimum temperature given measurements of the prior timepoints and attributes of the weather station."
      ],
      "metadata": {
        "id": "WEbYxwrygBm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the TensorFlow and pandas libraries:\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "sv2PA6UvesNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the dataset using the pandas read_csv function:\n",
        "df = pd.read_csv('Bias_correction_ucl.csv')"
      ],
      "metadata": {
        "id": "UZx-ASMtgNk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the Date column and drop any rows that have null\n",
        "# values:\n",
        "df.drop('Date', inplace=True, axis=1)\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "IjLjfHUxgRB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create target and feature datasets:\n",
        "target = df[['Next_Tmax', 'Next_Tmin']]\n",
        "features = df.drop(['Next_Tmax', 'Next_Tmin'],\n",
        "axis=1)\n",
        "# Rescale the feature dataset:\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "feature_array = scaler.fit_transform(features)\n",
        "features = pd.DataFrame(feature_array,\n",
        "columns=features.columns)"
      ],
      "metadata": {
        "id": "1ow1fwC9gYtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a Keras model of the Sequential class:\n",
        "model = tf.keras.Sequential()"
      ],
      "metadata": {
        "id": "g9KCGtlWgUiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an input layer to the model using the\n",
        "# model's add method, and set input_shape to the number of\n",
        "# columns in the feature dataset:\n",
        "model.add(tf.keras.layers.InputLayer\\\n",
        "(input_shape=(features.shape[1],), \\\n",
        "name='Input_layer'))"
      ],
      "metadata": {
        "id": "-wHBjb96ggY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add three hidden layers and an output layer of\n",
        "the Dense class to the model. The first hidden layer will\n",
        "have 16 units, the second will have 8 units, and the third will\n",
        "have 4 units. Label the layers appropriately. The output layer\n",
        "will have two units to match the target variable that has two\n",
        "columns:"
      ],
      "metadata": {
        "id": "AcX1AOP2gxK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dense(16,\n",
        "name='Dense_layer_1'))\n",
        "model.add(tf.keras.layers.Dense(8,\n",
        "name='Dense_layer_2'))\n",
        "model.add(tf.keras.layers.Dense(4,\n",
        "name='Dense_layer_3'))\n",
        "model.add(tf.keras.layers.Dense(2,\n",
        "name='Output_layer'))"
      ],
      "metadata": {
        "id": "1-kyzStlgnbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with an RMSprop optimizer and mean\n",
        "# squared error loss:\n",
        "model.compile(tf.optimizers.RMSprop(0.001),\n",
        "loss='mse')"
      ],
      "metadata": {
        "id": "CkUx0MDNg1ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a callback for TensorBoard:\n",
        "tensorboard_callback = tf.keras.callbacks\\\n",
        ".TensorBoard(log_dir=\"./logs\")"
      ],
      "metadata": {
        "id": "8dz1KP3dg5ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the training data for 50 epochs and add a\n",
        "# validation split equal to 20%:\n",
        "\n",
        "model.fit(x=features.to_numpy(),\n",
        "y=target.to_numpy(),\\\n",
        "epochs=50, callbacks=[tensorboard_callback], \\\n",
        "validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORuwMGFTg9nm",
        "outputId": "68288986-ec6d-484d-ef05-c44ae7cd3b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "190/190 [==============================] - 1s 3ms/step - loss: 347.1176 - val_loss: 83.8418\n",
            "Epoch 2/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 22.1582 - val_loss: 7.3016\n",
            "Epoch 3/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 5.6836 - val_loss: 5.5848\n",
            "Epoch 4/50\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 4.0211 - val_loss: 4.3650\n",
            "Epoch 5/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 3.2317 - val_loss: 3.7944\n",
            "Epoch 6/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 2.7818 - val_loss: 3.2459\n",
            "Epoch 7/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 2.5188 - val_loss: 3.0162\n",
            "Epoch 8/50\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 2.3455 - val_loss: 2.7753\n",
            "Epoch 9/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 2.2239 - val_loss: 2.8245\n",
            "Epoch 10/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 2.1185 - val_loss: 2.7777\n",
            "Epoch 11/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 2.0369 - val_loss: 2.4788\n",
            "Epoch 12/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.9759 - val_loss: 2.3771\n",
            "Epoch 13/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.9131 - val_loss: 2.7822\n",
            "Epoch 14/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.8665 - val_loss: 2.2872\n",
            "Epoch 15/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.8330 - val_loss: 2.5847\n",
            "Epoch 16/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.7968 - val_loss: 2.4076\n",
            "Epoch 17/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.7694 - val_loss: 2.0772\n",
            "Epoch 18/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.7319 - val_loss: 2.1675\n",
            "Epoch 19/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.7255 - val_loss: 2.0740\n",
            "Epoch 20/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6993 - val_loss: 2.1315\n",
            "Epoch 21/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6908 - val_loss: 2.4431\n",
            "Epoch 22/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6719 - val_loss: 1.9887\n",
            "Epoch 23/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6627 - val_loss: 2.0227\n",
            "Epoch 24/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6610 - val_loss: 2.1189\n",
            "Epoch 25/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6570 - val_loss: 1.9521\n",
            "Epoch 26/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6492 - val_loss: 1.9493\n",
            "Epoch 27/50\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6397 - val_loss: 2.3031\n",
            "Epoch 28/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6485 - val_loss: 1.9607\n",
            "Epoch 29/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6280 - val_loss: 2.4163\n",
            "Epoch 30/50\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6336 - val_loss: 1.9369\n",
            "Epoch 31/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6355 - val_loss: 1.9969\n",
            "Epoch 32/50\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6145 - val_loss: 1.9885\n",
            "Epoch 33/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6193 - val_loss: 1.8888\n",
            "Epoch 34/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6215 - val_loss: 1.9704\n",
            "Epoch 35/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6097 - val_loss: 1.8454\n",
            "Epoch 36/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6221 - val_loss: 1.9399\n",
            "Epoch 37/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6152 - val_loss: 2.6471\n",
            "Epoch 38/50\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6163 - val_loss: 1.8439\n",
            "Epoch 39/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6119 - val_loss: 2.5944\n",
            "Epoch 40/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6089 - val_loss: 1.8730\n",
            "Epoch 41/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6078 - val_loss: 1.8423\n",
            "Epoch 42/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6100 - val_loss: 1.8337\n",
            "Epoch 43/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6086 - val_loss: 1.8581\n",
            "Epoch 44/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6054 - val_loss: 1.8937\n",
            "Epoch 45/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6122 - val_loss: 1.8956\n",
            "Epoch 46/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6029 - val_loss: 2.0355\n",
            "Epoch 47/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6033 - val_loss: 1.9265\n",
            "Epoch 48/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6031 - val_loss: 2.0177\n",
            "Epoch 49/50\n",
            "190/190 [==============================] - 0s 2ms/step - loss: 1.6010 - val_loss: 1.8729\n",
            "Epoch 50/50\n",
            "190/190 [==============================] - 0s 1ms/step - loss: 1.6111 - val_loss: 2.3153\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff8fbc01fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data:\n",
        "loss = model.evaluate(features.to_numpy(),\n",
        "target.to_numpy())\n",
        "print('loss:', loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCY2V4HOhEyd",
        "outputId": "60b3b699-c72e-4b33-9de8-d9b7e86347f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "238/238 [==============================] - 0s 2ms/step - loss: 1.8215\n",
            "loss: 1.8214621543884277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "you have created an ANN with multiple hidden\n",
        "layers. The loss you obtained was lower than that achieved using\n",
        "linear regression, which demonstrates the power of ANNs. With some\n",
        "tuning to the hyperparameters (such as varying the number of layers,\n",
        "the number of units within each layer, adding activation functions,\n",
        "and changing the loss and optimizer), the loss could be even lower."
      ],
      "metadata": {
        "id": "lX4RPArthiEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Logistic Regression Model as an ANN with TensorFlow"
      ],
      "metadata": {
        "id": "AxATdf_HhoU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "you will create a logistic regression model as an ANN\n",
        "using TensorFlow. The dataset, qsar_androgen_receptor.csv, is\n",
        "used to develop classification models for the discrimination of\n",
        "binder/non-binder molecules given various attributes of the\n",
        "molecules. Here, the molecule attributes represent the features of\n",
        "your dataset, and their binding properties represent the target\n",
        "variable, in which a positive value represents a binding molecule, and\n",
        "a negative value represents a non-binding molecule. You will create a\n",
        "logistic regression model to predict the binding properties of the\n",
        "molecule given attributes of the molecule provided in the dataset."
      ],
      "metadata": {
        "id": "IcdDXS9ph9JA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the TensorFlow and pandas libraries:\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "LhP-b-bzhXwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the dataset using the pandas read_csv function:\n",
        "df = pd.read_csv('qsar_androgen_receptor.csv', \\\n",
        "sep=';')"
      ],
      "metadata": {
        "id": "jtSu7WSCiLbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop any rows that have null values:\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "0a5qdJS0iQ0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[https://towardsdatascience.com/apply-and-lambda-usage-in-pandas-b13a1ea037f7](https://) \n",
        "for apply lamda pandas \n"
      ],
      "metadata": {
        "id": "jGDAQaHDjQ3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create target and feature datasets:\n",
        "target = df['positive'].apply(lambda x: 1 if\n",
        "x=='positive' else 0)\n",
        "features = df.drop('positive', axis=1)"
      ],
      "metadata": {
        "id": "LLYThf5CiWpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a Keras model of the Sequential class:\n",
        "model = tf.keras.Sequential()"
      ],
      "metadata": {
        "id": "XbOTPbu7jfDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an input layer to the model using the\n",
        "# model's add method and set input_shape to be the number\n",
        "# of columns in the feature dataset:\n",
        "model.add(tf.keras.layers.InputLayer\\\n",
        "(input_shape=(features.shape[1],), \\\n",
        "name='Input_layer'))"
      ],
      "metadata": {
        "id": "QA-DMsN4iieS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the output layer of the Dense class to the model with a\n",
        "# size of 1, representing the target variable:\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1,\n",
        "name='Output_layer', \\\n",
        "activation='sigmoid')\n",
        ")"
      ],
      "metadata": {
        "id": "Jbgg5D0pjlLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with an RMSprop optimizer and binary\n",
        "# cross-entropy for the loss, and compute the accuracy:\n",
        "\n",
        "model.compile(tf.optimizers.RMSprop(0.0001), \\\n",
        "loss='binary_crossentropy',\n",
        "metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dbEyZi0qjsfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TensorBoard callback:\n",
        "\n",
        "tensorboard_callback =tf.keras.callbacks.TensorBoard\\\n",
        "(log_dir=\"./logs\")"
      ],
      "metadata": {
        "id": "ivHeijH4jw_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the training data for 50 epochs, adding the\n",
        "# TensorBoard callback with a validation split of 20%:\n",
        "\n",
        "model.fit(x=features.to_numpy(), y=target.to_numpy(),\\\n",
        "epochs=50, callbacks=[tensorboard_callback], \\\n",
        "validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqTloElCj2mY",
        "outputId": "04bb692c-0ec5-426b-a069-171f0d6ae646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "43/43 [==============================] - 1s 8ms/step - loss: 0.6950 - accuracy: 0.5312 - val_loss: 0.5673 - val_accuracy: 0.8107\n",
            "Epoch 2/50\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.6290 - accuracy: 0.6958 - val_loss: 0.4831 - val_accuracy: 0.8905\n",
            "Epoch 3/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7864 - val_loss: 0.4249 - val_accuracy: 0.9142\n",
            "Epoch 4/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.8353 - val_loss: 0.3885 - val_accuracy: 0.9260\n",
            "Epoch 5/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.8546 - val_loss: 0.3627 - val_accuracy: 0.9260\n",
            "Epoch 6/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8613 - val_loss: 0.3451 - val_accuracy: 0.9260\n",
            "Epoch 7/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8680 - val_loss: 0.3320 - val_accuracy: 0.9260\n",
            "Epoch 8/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8702 - val_loss: 0.3230 - val_accuracy: 0.9260\n",
            "Epoch 9/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8709 - val_loss: 0.3149 - val_accuracy: 0.9260\n",
            "Epoch 10/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8709 - val_loss: 0.3089 - val_accuracy: 0.9260\n",
            "Epoch 11/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8709 - val_loss: 0.3030 - val_accuracy: 0.9260\n",
            "Epoch 12/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8709 - val_loss: 0.2993 - val_accuracy: 0.9260\n",
            "Epoch 13/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8709 - val_loss: 0.2944 - val_accuracy: 0.9260\n",
            "Epoch 14/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8717 - val_loss: 0.2908 - val_accuracy: 0.9260\n",
            "Epoch 15/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8717 - val_loss: 0.2879 - val_accuracy: 0.9260\n",
            "Epoch 16/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8717 - val_loss: 0.2859 - val_accuracy: 0.9260\n",
            "Epoch 17/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8717 - val_loss: 0.2828 - val_accuracy: 0.9260\n",
            "Epoch 18/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8717 - val_loss: 0.2812 - val_accuracy: 0.9260\n",
            "Epoch 19/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8724 - val_loss: 0.2793 - val_accuracy: 0.9231\n",
            "Epoch 20/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8724 - val_loss: 0.2777 - val_accuracy: 0.9231\n",
            "Epoch 21/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8724 - val_loss: 0.2780 - val_accuracy: 0.9231\n",
            "Epoch 22/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8731 - val_loss: 0.2766 - val_accuracy: 0.9231\n",
            "Epoch 23/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8739 - val_loss: 0.2751 - val_accuracy: 0.9231\n",
            "Epoch 24/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8739 - val_loss: 0.2742 - val_accuracy: 0.9231\n",
            "Epoch 25/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8739 - val_loss: 0.2737 - val_accuracy: 0.9260\n",
            "Epoch 26/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8761 - val_loss: 0.2728 - val_accuracy: 0.9260\n",
            "Epoch 27/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8791 - val_loss: 0.2742 - val_accuracy: 0.9290\n",
            "Epoch 28/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8820 - val_loss: 0.2738 - val_accuracy: 0.9290\n",
            "Epoch 29/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8835 - val_loss: 0.2738 - val_accuracy: 0.9260\n",
            "Epoch 30/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8850 - val_loss: 0.2736 - val_accuracy: 0.9260\n",
            "Epoch 31/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8858 - val_loss: 0.2756 - val_accuracy: 0.9201\n",
            "Epoch 32/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8865 - val_loss: 0.2745 - val_accuracy: 0.9201\n",
            "Epoch 33/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8880 - val_loss: 0.2756 - val_accuracy: 0.9231\n",
            "Epoch 34/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8887 - val_loss: 0.2767 - val_accuracy: 0.9260\n",
            "Epoch 35/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8939 - val_loss: 0.2772 - val_accuracy: 0.9260\n",
            "Epoch 36/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8969 - val_loss: 0.2781 - val_accuracy: 0.9320\n",
            "Epoch 37/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8976 - val_loss: 0.2782 - val_accuracy: 0.9349\n",
            "Epoch 38/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8991 - val_loss: 0.2792 - val_accuracy: 0.9379\n",
            "Epoch 39/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.9006 - val_loss: 0.2806 - val_accuracy: 0.9379\n",
            "Epoch 40/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.9013 - val_loss: 0.2796 - val_accuracy: 0.9349\n",
            "Epoch 41/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.9013 - val_loss: 0.2814 - val_accuracy: 0.9320\n",
            "Epoch 42/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.9006 - val_loss: 0.2812 - val_accuracy: 0.9290\n",
            "Epoch 43/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.9013 - val_loss: 0.2813 - val_accuracy: 0.9290\n",
            "Epoch 44/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.9021 - val_loss: 0.2836 - val_accuracy: 0.9260\n",
            "Epoch 45/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.9043 - val_loss: 0.2829 - val_accuracy: 0.9260\n",
            "Epoch 46/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.9050 - val_loss: 0.2828 - val_accuracy: 0.9290\n",
            "Epoch 47/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.9058 - val_loss: 0.2840 - val_accuracy: 0.9231\n",
            "Epoch 48/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.9058 - val_loss: 0.2863 - val_accuracy: 0.9231\n",
            "Epoch 49/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.9073 - val_loss: 0.2869 - val_accuracy: 0.9201\n",
            "Epoch 50/50\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.9073 - val_loss: 0.2877 - val_accuracy: 0.9201\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff8fba02890>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data:\n",
        "\n",
        "loss, accuracy = model.evaluate(features.to_numpy(),\n",
        "\\\n",
        "target.to_numpy())\n",
        "print(f'loss: {loss}, accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpB6RkrTkBRd",
        "outputId": "289a3167-e2e3-4477-b9b8-20febf295de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.9098\n",
            "loss: 0.2782171070575714, accuracy: 0.909845769405365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "you have learned how to build a classification model\n",
        "to discriminate between the binding properties of various molecules\n",
        "based on their other molecular attributes. The classification model\n",
        "\n",
        "was equivalent to a logistic regression model since it had only one\n",
        "layer and was preceded by a sigmoid activation function. With only\n",
        "one layer, there is a weight for each input feature and a single value\n",
        "for the bias. The sigmoid activation function transforms the output of\n",
        "the layer into a value between 0 and 1, which is then rounded to\n",
        "represent your two classes. 0.5 and above represents one class, the\n",
        "molecule with binding properties, and below 0.5 represents the other\n",
        "class, molecules with non-binding properties."
      ],
      "metadata": {
        "id": "revusJSvkN4b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "osctksIHkGOt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}